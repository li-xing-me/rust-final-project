use std::sync::atomic::{AtomicUsize, Ordering};
use std::sync::Arc;
use tokio::time::{self, Duration};
use dashmap::DashMap;

/// è´Ÿè½½å‡è¡¡å™¨çŠ¶æ€
#[derive(Debug, Clone)]
pub struct LoadBalancer {
    /// å½“å‰æ´»è·ƒè¯·æ±‚æ•°
    active_requests: Arc<AtomicUsize>,
    /// å½“å‰workerçº¿ç¨‹æ•°ï¼ˆå¯åŠ¨æ€è°ƒæ•´ï¼‰
    current_worker_threads: Arc<AtomicUsize>,
    /// å†å²è´Ÿè½½æ•°æ®ï¼ˆç”¨äºè¶‹åŠ¿åˆ†æï¼‰
    load_history: Arc<DashMap<String, Vec<usize>>>,
    /// é…ç½®å‚æ•°
    config: LoadBalancerConfig,
}

/// è´Ÿè½½å‡è¡¡å™¨é…ç½®
#[derive(Debug, Clone)]
pub struct LoadBalancerConfig {
    /// ä½è´Ÿè½½é˜ˆå€¼ï¼ˆè¯·æ±‚æ•°ä½äºæ­¤å€¼ä¸ºä½è´Ÿè½½ï¼‰
    pub low_load_threshold: usize,
    /// é«˜è´Ÿè½½é˜ˆå€¼ï¼ˆè¯·æ±‚æ•°é«˜äºæ­¤å€¼ä¸ºé«˜è´Ÿè½½ï¼‰
    pub high_load_threshold: usize,
    /// æ£€æŸ¥é—´éš”ï¼ˆæ¯«ç§’ï¼‰
    pub check_interval_ms: u64,
    /// æœ€å¤§è®¡ç®—çº¿ç¨‹æ•°
    pub max_compute_threads: usize,
    /// æœ€å¤§æŸ¥è¯¢çº¿ç¨‹æ•°
    pub max_query_threads: usize,
}

impl Default for LoadBalancerConfig {
    fn default() -> Self {
        Self {
            low_load_threshold: 5,
            high_load_threshold: 20,
            check_interval_ms: 5000,  // 5ç§’
            max_compute_threads: 4,
            max_query_threads: 8,
        }
    }
}

impl LoadBalancer {
    /// åˆ›å»ºæ–°çš„è´Ÿè½½å‡è¡¡å™¨
    pub fn new(config: LoadBalancerConfig) -> Self {
        let initial_threads = config.max_query_threads;

        Self {
            active_requests: Arc::new(AtomicUsize::new(0)),
            current_worker_threads: Arc::new(AtomicUsize::new(initial_threads)),
            load_history: Arc::new(DashMap::new()),
            config,
        }
    }

    /// å¢åŠ æ´»è·ƒè¯·æ±‚è®¡æ•°
    pub fn increment_request(&self) {
        self.active_requests.fetch_add(1, Ordering::SeqCst);
    }

    /// å‡å°‘æ´»è·ƒè¯·æ±‚è®¡æ•°
    pub fn decrement_request(&self) {
        self.active_requests.fetch_sub(1, Ordering::SeqCst);
    }

    /// è·å–å½“å‰æ´»è·ƒè¯·æ±‚æ•°
    pub fn get_active_requests(&self) -> usize {
        self.active_requests.load(Ordering::SeqCst)
    }

    /// è·å–å½“å‰è´Ÿè½½çº§åˆ«
    pub fn get_load_level(&self) -> LoadLevel {
        let current = self.get_active_requests();

        if current < self.config.low_load_threshold {
            LoadLevel::Low
        } else if current > self.config.high_load_threshold {
            LoadLevel::High
        } else {
            LoadLevel::Normal
        }
    }

    /// è·å–å½“å‰workerçº¿ç¨‹æ•°
    pub fn get_current_worker_threads(&self) -> usize {
        self.current_worker_threads.load(Ordering::SeqCst)
    }

    /// åŠ¨æ€è°ƒæ•´workerçº¿ç¨‹æ•°ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼‰
    pub fn adjust_worker_threads(&self) -> usize {
        let current_load = self.get_active_requests();
        let load_level = self.get_load_level();
        let current_threads = self.get_current_worker_threads();

        // æ ¹æ®è´Ÿè½½çº§åˆ«è°ƒæ•´çº¿ç¨‹æ•°
        let new_threads = match load_level {
            LoadLevel::Low => {
                // ä½è´Ÿè½½ï¼šå‡å°‘çº¿ç¨‹æ•°ï¼ˆä½†è‡³å°‘ä¿ç•™2ä¸ªï¼‰
                2.max(self.config.max_query_threads / 2)
            }
            LoadLevel::Normal => {
                // æ­£å¸¸è´Ÿè½½ï¼šæ ¹æ®å½“å‰è¯·æ±‚æ•°è°ƒæ•´
                if current_load < 5 {
                    self.config.max_query_threads / 2
                } else {
                    self.config.max_query_threads * 2 / 3
                }
            }
            LoadLevel::High => {
                // é«˜è´Ÿè½½ï¼šæœ€å¤§åŒ–æŸ¥è¯¢çº¿ç¨‹
                self.config.max_query_threads
            }
        };

        // é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
        let new_threads = new_threads.clamp(2, self.config.max_query_threads);

        // å¦‚æœçº¿ç¨‹æ•°æœ‰å˜åŒ–ï¼Œè®°å½•æ—¥å¿—
        if new_threads != current_threads {
            self.current_worker_threads.store(new_threads, Ordering::SeqCst);
            log::info!(
                "Adjusted worker threads: {} -> {} (load: {}, active requests: {})",
                current_threads,
                new_threads,
                match load_level {
                    LoadLevel::Low => "Low",
                    LoadLevel::Normal => "Normal",
                    LoadLevel::High => "High",
                },
                current_load
            );
        }

        new_threads
    }
    /// è®¡ç®—åº”è¯¥åˆ†é…ç»™è®¡ç®—ï¼ˆæŒ–çŸ¿ï¼‰çš„çº¿ç¨‹æ•°
    pub fn calculate_compute_threads(&self) -> usize {
        let total_threads = self.config.max_compute_threads + self.config.max_query_threads;
        let query_threads = self.get_current_worker_threads();

        // å‰©ä½™çº¿ç¨‹ç»™è®¡ç®—ï¼ˆè‡³å°‘ä¿ç•™1ä¸ªï¼‰
        total_threads.saturating_sub(query_threads).max(1)
    }

    /// è®¡ç®—åº”è¯¥åˆ†é…ç»™æŸ¥è¯¢çš„çº¿ç¨‹æ•°
    pub fn calculate_query_threads(&self) -> usize {
        self.get_current_worker_threads()
    }

    /// è®°å½•è´Ÿè½½å†å²ï¼ˆç”¨äºåˆ†æå’Œè°ƒè¯•ï¼‰
    pub fn record_load_history(&self) {
        let current = self.get_active_requests();
        let timestamp = chrono::Local::now().format("%H:%M:%S").to_string();

        self.load_history
            .entry("active_requests".to_string())
            .or_insert_with(Vec::new)
            .push(current);

        // é™åˆ¶å†å²è®°å½•é•¿åº¦
        if let Some(mut history) = self.load_history.get_mut("active_requests") {
            if history.len() > 100 {
                history.remove(0);
            }
        }

        log::debug!(
            "Load stats - Active: {}, Level: {:?}, Compute threads: {}, Query threads: {}",
            current,
            self.get_load_level(),
            self.calculate_compute_threads(),
            self.calculate_query_threads()
        );
    }

    /// å¯åŠ¨è´Ÿè½½ç›‘æ§ä»»åŠ¡
    pub async fn start_monitoring(self: Arc<Self>) {
        log::info!("Starting load balancer monitoring and auto-adjustment");

        let mut interval = time::interval(Duration::from_millis(self.config.check_interval_ms));

        loop {
            interval.tick().await;

            // 1. è®°å½•å½“å‰è´Ÿè½½
            self.record_load_history();

            // 2. åŠ¨æ€è°ƒæ•´çº¿ç¨‹æ•°ï¼ˆæ ¸å¿ƒï¼‰
            self.adjust_worker_threads();

            // 3. æ ¹æ®è´Ÿè½½çº§åˆ«è®°å½•æ—¥å¿—
            let load_level = self.get_load_level();
            let current_load = self.get_active_requests();
            let current_threads = self.get_current_worker_threads();

            match load_level {
                LoadLevel::Low => {
                    log::debug!("ğŸ”µ Low load: {} requests, {} worker threads",
                        current_load, current_threads);
                }
                LoadLevel::Normal => {
                    log::debug!("ğŸŸ¢ Normal load: {} requests, {} worker threads",
                        current_load, current_threads);
                }
                LoadLevel::High => {
                    log::warn!("ğŸ”´ High load: {} requests, {} worker threads",
                        current_load, current_threads);
                }
            }
        }
    }

    /// è·å–è´Ÿè½½ç»Ÿè®¡ä¿¡æ¯
    pub fn get_stats(&self) -> LoadBalancerStats {
        let current = self.get_active_requests();
        let level = self.get_load_level();

        let avg_load = if let Some(history) = self.load_history.get("active_requests") {
            if !history.is_empty() {
                history.iter().sum::<usize>() / history.len()
            } else {
                0
            }
        } else {
            0
        };

        LoadBalancerStats {
            active_requests: current,
            load_level: level,
            recommended_compute_threads: self.calculate_compute_threads(),
            recommended_query_threads: self.calculate_query_threads(),
            average_load: avg_load,
            history_size: self.load_history.get("active_requests")
                .map(|h| h.len())
                .unwrap_or(0),
        }
    }
}

/// è´Ÿè½½çº§åˆ«
#[derive(Debug, Clone, Copy, PartialEq)]
pub enum LoadLevel {
    Low,
    Normal,
    High,
}

/// è´Ÿè½½ç»Ÿè®¡ä¿¡æ¯
#[derive(Debug, Clone)]
pub struct LoadBalancerStats {
    pub active_requests: usize,
    pub load_level: LoadLevel,
    pub recommended_compute_threads: usize,
    pub recommended_query_threads: usize,
    pub average_load: usize,
    pub history_size: usize,
}